\section{Problem}


% --- SLIDE 1: Problem Statement ---
\begin{frame}{Problem Statement}
\begin{itemize}
    \item<1-> \textcolor{blue}{Kernel density estimation (KDE)} is a flexible nonparametric method.
    \item<2-> \textcolor{orange}{Univariate KDE} is well understood and easy to implement.
    \item<3-> In practice, data are often \textcolor{purple}{multivariate}.
    \item<4-> This motivates extending KDE to \textcolor{teal}{$p$-dimensional spaces}.
\end{itemize}
\end{frame}


% --- SLIDE 2: THE PROBLEM ---
\begin{frame}{The Curse of Dimensionality}
    \begin{columns}
        % Left Column: Concepts
        \begin{column}{0.5\textwidth}
            \begin{alertblock}{The Challenge}
                High-dimensional space ($p > 3$) is vastly different from univariate space.
                Data becomes incredibly \textbf{sparse}.
            \end{alertblock}

            \pause

            \vspace{1em}
            \textbf{Key Implications:}
            \begin{itemize}
                \item Points have very few near neighbors.
                \item ``Empty space'' phenomenon: For $p=10$, $>50\%$ of mass lies in the extreme tails ($>1.6\sigma$).
                \item Visualization is difficult without dimension reduction.
            \end{itemize}
        \end{column}

        % Right Column: Visual
        \begin{column}{0.5\textwidth}
            \centering
            \includegraphics[width=0.9\linewidth]{sparseness_highdim}

            \vspace{0.3em}
            \captionof{figure}{\scriptsize Sparseness in High Dimensions}
        \end{column}
    \end{columns}
\end{frame}
